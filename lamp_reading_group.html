<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Desmond Elliott at the University of Copenhagen</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/1-col-portfolio.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="index.html">Desmond Elliott</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    <li>
                        <a href="about.html">About</a>
                    </li>
		    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">LAMP <span class="caret"></span></a>
                        <ul class="dropdown-menu">
		            <li><a href="lamp_about.html">Projects</a></li>
                            <li><a href="lamp_reading_group.html">Reading group</a></li>
                        </ul>
                    </li>
                    <li>
                        <a href="publications.html">Papers</a>
                    </li>
                    <li>
                        <a href="talks.html">Talks</a>
                    </li>
                    <li>
                        <a href="people.html">People</a>
                    </li>
                    <li>
                        <a href="teaching.html">Teaching</a>
                    </li>
                    <li>
                        <a href="service.html">Service</a>
                    </li>
                    <li>
			<a href="talks.html">Talks</a>
		    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Content -->
    <div class="container">
	  <div class='col-md-8'>
	      <h3>Reading Group and Schedule</h3>
	      <p>
              We have a semi-regular reading group over Zoom on Wednesdays from 1500--1600 UTC.
              </p>
	      <style type="text/css">
	      .tg  {border-collapse:collapse;border-spacing:0;}
	      .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
	        overflow:hidden;padding:10px 5px;word-break:normal;}
	      .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
	        font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
	      .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
	      .tg .tg-0pkz{border-color:inherit;text-align:left;vertical-align:top;min-width:60px;}
	      </style>
              <table class="tg">
              <thead>
                <tr>
                  <td class="tg-0pkz" style="font-weight:bold;">Date</td>
                  <td class="tg-0pky" style="font-weight:bold;">Paper</td>
                  <td class="tg-0pky" style="font-weight:bold;">Lead</td>
                </tr>
              </thead>
              <tbody>
 		<tr>
                  <td class="tg-0pkz">12 Oct <br/>2022</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2209.14500">Bidirectional Language Models Are Also Few-shot Learners</a>. Patel et al. 2022</td>
                  <td class="tg-0pky">Wenyan</td>
                </tr>		      
		<tr>
                  <td class="tg-0pkz">21 Sep <br/>2022</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2012.11995">DP-Parse: Finding Word Boundaries from Raw Speech with an Instance Lexicon</a>. Algayres et al. 2022</td>
                  <td class="tg-0pky">Ramon</td>
                </tr>		      
                <tr>
                  <td class="tg-0pkz">24 Nov <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2104.08313">Does language help generalization in vision models?</a> Devillers et al. 2021</td>
                  <td class="tg-0pky">Dan</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">27 Oct <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2012.11995">Pre-Training a Language Model Without Human Language</a>. Chiang and Lee 2020</td>
                  <td class="tg-0pky">Ramon</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">29 Sep <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2104.00743">Towards General Purpose Vision Systems</a>. Gupta et al. 2021</td>
                  <td class="tg-0pky">Rita</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">15 Sep <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2106.13884">Multimodal Few-Shot Learning with Frozen Language Models</a>. Tsimpoukelli et al. 2021</td>
                  <td class="tg-0pky">Emanuele</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">16 Jun <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2106.02192">Grounding ‘Grounding’ in NLP</a>. Chandu et al. 2021.</td>
                  <td class="tg-0pky">Ramon</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">26 May <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2105.06453">Episodic Transformer for Vision-and-Language Navigation</a>. Pashevich et al. 2021.</td>
                  <td class="tg-0pky">Dylan</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">21 Apr <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2102.02779">Unifying Vision-and-Language Tasks via Text Generation</a>. Cho et al. 2021.</td>
                  <td class="tg-0pky">Rita</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">7 Apr <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2103.08493">How Many Data Points is a Prompt Worth?</a>. Le Scao and Rush 2021.</td>
                  <td class="tg-0pky">Erkut</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">24 Mar <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From Natural Language Supervision</a>. Radford et al. 2021.</td>
                  <td class="tg-0pky">Aykut</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">24 Feb <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/pdf/2005.07310">Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models</a>. Cao et al. 2020.</td>
                  <td class="tg-0pky">Des</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">10 Feb <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2012.15409">UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning</a>. Li et al. 2020.</td>
                  <td class="tg-0pky">Emanuele</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">27 Jan <br/>2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2101.00529">VinVL: Making Visual Representations Matter in Vision-Language Models</a>. Zhang et al. 2021.</td>
                  <td class="tg-0pky">Semih</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">13 Jan <br/> 2021</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2010.09890">Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration</a>. Puig et al. 2020.</td>
                  <td class="tg-0pky">Ramon</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">25 Nov <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2010.06775" target="_blank" rel="noopener noreferrer">Language Grounds Experience</a>. Bisk et al. 2020.</td>
                  <td class="tg-0pky">Semih</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">28 Oct <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2010.06775" target="_blank" rel="noopener noreferrer">Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision</a>. Tan and Bansal 2020.</td>
                  <td class="tg-0pky">Des</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">14 Oct <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2009.01719" target="_blank" rel="noopener noreferrer">Grounded Language Learning Fast and Slow</a>. Hill et al. 2020.</td>
                  <td class="tg-0pky">Łukasz</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">30 Sep <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2017.02124/full" target="_blank" rel="noopener noreferrer">A Developmental Approach to Machine Learning?</a> Smith and Slone 2017.</td>
                  <td class="tg-0pky">Łukasz</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">9 Sep <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2008.01392" target="_blank" rel="noopener noreferrer">Learning Visual Representations with Caption Annotations</a>.&nbsp;&nbsp;Sariyildiz et al. 2020.</td>
                  <td class="tg-0pky">???</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">26 Aug <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/2005.00619" target="_blank" rel="noopener noreferrer">Probing Text Models for Common Ground with Visual Representations</a><span style="font-weight:400;font-style:normal">. Ilharco et al. 2020.</span></td>
                  <td class="tg-0pky">Erkut</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">15 Jul <br/> 2020</td>
                  <td class="tg-0pky"><a href="https://arxiv.org/abs/1911.11237" target="_blank" rel="noopener noreferrer">Learning to Learn Words from Visual Scenes</a>. Surís et al. 2019.</td>
                  <td class="tg-0pky">Aykut</td>
                </tr>
                <tr>
                  <td class="tg-0pkz">24 Jun<br/> 2020</td>
                  <td class="tg-0pky"><a href="https://www.sciencedirect.com/science/article/abs/pii/0167278990900876" target="_blank" rel="noopener noreferrer">The symbol grounding problem</a>. Harnad 1990.</td>
                  <td class="tg-0pky">Des</td>
                </tr>
              </tbody>
              </table>
	  </div>
    </div>

    </div>
    <!-- /.container -->
    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>
